import time
import random
import sys
import re
import os
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

BASE_URL = "https://govolunteerhcmc.vn"
FALLBACK_IMAGE_URL = "https://govolunteerhcmc.vn/wp-content/uploads/2024/02/logo-gv-tron.png"

def setup_driver():
    """C·∫•u h√¨nh Chrome Driver m·ªôt c√°ch ƒë√°ng tin c·∫≠y cho m√¥i tr∆∞·ªùng Render."""
    chrome_options = Options()
    
    # Render t·ª± ƒë·ªông ƒë·∫∑t c√°c bi·∫øn m√¥i tr∆∞·ªùng n√†y sau khi c√†i buildpack
    chrome_options.binary_location = os.environ.get("GOOGLE_CHROME_BIN")
    
    # C√°c t√πy ch·ªçn b·∫Øt bu·ªôc ƒë·ªÉ ch·∫°y trong m√¥i tr∆∞·ªùng container (server)
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    
    print("üöÄ ƒêang kh·ªüi t·∫°o Selenium Driver v·ªõi ƒë∆∞·ªùng d·∫´n t·ª´ buildpack...")
    try:
        # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n chromedriver do Render cung c·∫•p
        service = Service(executable_path=os.environ.get("CHROMEDRIVER_PATH"))
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(30)
        print("‚úÖ Selenium Driver ƒë√£ s·∫µn s√†ng.")
        return driver
    except Exception as e:
        print(f"‚ùå L·ªñI KH·ªûI T·∫†O DRIVER: {e}", file=sys.stderr)
        print("--- G·ª¢I √ù G·ª† L·ªñI ---", file=sys.stderr)
        print("1. ƒê·∫£m b·∫£o b·∫°n ƒë√£ th√™m 2 buildpack (google-chrome v√† chromedriver) tr√™n Render.", file=sys.stderr)
        print("2. ƒê·∫£m b·∫£o bi·∫øn m√¥i tr∆∞·ªùng GOOGLE_CHROME_BIN v√† CHROMEDRIVER_PATH ƒë∆∞·ª£c Render t·ª± ƒë·ªông thi·∫øt l·∫≠p.", file=sys.stderr)
        return None

def get_high_res_image_url(url: str):
    if not url: return FALLBACK_IMAGE_URL
    return re.sub(r'-\d{2,4}x\d{2,4}(?=\.\w+$)', '', url)

def scrape_news():
    driver = setup_driver()
    if not driver: return None

    try:
        driver.get(BASE_URL)
        time.sleep(5)
        soup = BeautifulSoup(driver.page_source, "lxml")
        # ... (Ph·∫ßn logic parse c√≤n l·∫°i gi·ªØ nguy√™n) ...
        sections = []
        for sec in soup.select("section.elementor-section.elementor-top-section"):
            h2 = sec.select_one("h2.elementor-heading-title.elementor-size-default")
            if not h2 or not h2.text.strip(): continue
            category = h2.text.strip()
            articles = []
            for post in sec.select("article.elementor-post"):
                a = post.select_one("h3.elementor-post__title a")
                if not a or not a.get('href', '').startswith(BASE_URL): continue
                img = post.select_one(".elementor-post__thumbnail img")
                image_url = get_high_res_image_url(img['src']) if img and img.get('src') else FALLBACK_IMAGE_URL
                ex = post.select_one(".elementor-post__excerpt p")
                excerpt = ex.text.strip() if ex else None
                articles.append({"title": a.text.strip(), "link": a['href'], "imageUrl": image_url, "excerpt": excerpt})
            if articles:
                sections.append({"category": category, "articles": list({article['link']: article for article in articles}.values())})
        print(f"‚úÖ L·∫•y d·ªØ li·ªáu trang ch·ªß th√†nh c√¥ng, t√¨m th·∫•y {len(sections)} m·ª•c.")
        return list({section['category']: section for section in sections}.values())
    except Exception as e:
        print(f"‚ùå L·ªói khi scraping trang ch·ªß: {e}", file=sys.stderr)
        return None
    finally:
        driver.quit()

def scrape_article_content(article_url: str):
    driver = setup_driver()
    if not driver: return None
    try:
        driver.get(article_url)
        time.sleep(3)
        content_div = driver.find_element(by="css selector", value=".elementor-widget-theme-post-content")
        html_content = content_div.get_attribute('outerHTML')
        print("‚úÖ L·∫•y n·ªôi dung b√†i vi·∫øt th√†nh c√¥ng!")
        return html_content
    except Exception as e:
        print(f"‚ùå L·ªói khi scraping b√†i vi·∫øt: {e}", file=sys.stderr)
        return None
    finally:
        driver.quit()
