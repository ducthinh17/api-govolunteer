
import time
import random
import sys
import re
import os
import requests # Gi·ªØ l·∫°i requests cho trang news
from bs4 import BeautifulSoup

# Import c√°c th∆∞ vi·ªán c·ªßa Selenium ch·ªâ khi c·∫ßn thi·∫øt
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

# --- C·∫•u h√¨nh chung ---
BASE_URL = "https://govolunteerhcmc.vn"
FALLBACK_IMAGE_URL = "https://govolunteerhcmc.vn/wp-content/uploads/2024/02/logo-gv-tron.png"

def get_high_res_image_url(url: str):
    """Lo·∫°i b·ªè c√°c h·∫≠u t·ªë k√≠ch th∆∞·ªõc ·∫£nh ƒë·ªÉ l·∫•y ·∫£nh g·ªëc."""
    if not url: return FALLBACK_IMAGE_URL
    return re.sub(r'-\d{2,4}x\d{2,4}(?=\.\w+$)', '', url)

# --- PHI√äN B·∫¢N C≈® C·ª¶A B·∫†N (ƒê√É T·ªêI ∆ØU) CHO /NEWS ---
def scrape_news():
    """
    S·ª≠ d·ª•ng `requests` ƒë·ªÉ l·∫•y d·ªØ li·ªáu trang ch·ªß m·ªôt c√°ch nhanh ch√≥ng.
    """
    print("üöÄ S·ª≠ d·ª•ng `requests` ƒë·ªÉ l·∫•y d·ªØ li·ªáu /news...")
    headers = {
        'User-Agent': f'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
        'Referer': 'https://www.google.com/'
    }
    try:
        response = requests.get(BASE_URL, headers=headers, timeout=15)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"‚ùå L·ªói khi d√πng requests: {e}", file=sys.stderr)
        return []

    soup = BeautifulSoup(response.text, "lxml")
    sections = []
    
    for sec in soup.select("section.elementor-section.elementor-top-section"):
        h2 = sec.select_one("h2.elementor-heading-title.elementor-size-default")
        if not h2 or not h2.text.strip():
            continue
        
        category = h2.text.strip()
        articles = []
        
        for post in sec.select("article.elementor-post"):
            a = post.select_one("h3.elementor-post__title a")
            if not a or not a.get('href', '').startswith(BASE_URL):
                continue

            img = post.select_one(".elementor-post__thumbnail img")
            image_url = get_high_res_image_url(img['src']) if img and img.get('src') else FALLBACK_IMAGE_URL
            
            ex = post.select_one(".elementor-post__excerpt p")
            excerpt = ex.text.strip() if ex else None
            
            articles.append({
                "title": a.text.strip(),
                "link": a['href'],
                "imageUrl": image_url,
                "excerpt": excerpt,
            })
            
        if articles:
            unique_articles = list({article['link']: article for article in articles}.values())
            sections.append({"category": category, "articles": unique_articles})
            
    print(f"‚úÖ L·∫•y d·ªØ li·ªáu /news th√†nh c√¥ng, t√¨m th·∫•y {len(sections)} m·ª•c.")
    return list({section['category']: section for section in sections}.values())


# --- PHI√äN B·∫¢N N√ÇNG C·∫§P D√ôNG SELENIUM CHO /ARTICLE ---
def setup_selenium_driver():
    """C·∫•u h√¨nh Chrome Driver cho m√¥i tr∆∞·ªùng Render."""
    chrome_options = Options()
    chrome_bin = os.environ.get("GOOGLE_CHROME_BIN", "/app/.apt/usr/bin/google-chrome")
    driver_path = os.environ.get("CHROMEDRIVER_PATH", "/app/.chromedriver/bin/chromedriver")
    
    chrome_options.binary_location = chrome_bin
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    
    print("üöÄ ƒêang kh·ªüi t·∫°o Selenium Driver cho t√°c v·ª• /article...")
    try:
        service = Service(executable_path=driver_path)
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(30)
        print("‚úÖ Selenium Driver ƒë√£ s·∫µn s√†ng.")
        return driver
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o Selenium Driver: {e}", file=sys.stderr)
        return None

def scrape_article_content(article_url: str):
    """
    S·ª≠ d·ª•ng Selenium ƒë·ªÉ ƒë·∫£m b·∫£o l·∫•y ƒë∆∞·ª£c n·ªôi dung chi ti·∫øt c·ªßa b√†i vi·∫øt.
    """
    driver = setup_selenium_driver()
    if not driver: 
        return None

    try:
        print(f"üìÑ ƒêang truy c·∫≠p b√†i vi·∫øt b·∫±ng Selenium: {article_url}")
        driver.get(article_url)
        time.sleep(3)
        
        content_div = driver.find_element(by="css selector", value=".elementor-widget-theme-post-content")
        html_content = content_div.get_attribute('outerHTML')
        print("‚úÖ L·∫•y n·ªôi dung b√†i vi·∫øt th√†nh c√¥ng!")
        return html_content
    except Exception as e:
        print(f"‚ùå L·ªói khi scraping b√†i vi·∫øt: {e}", file=sys.stderr)
        return None
    finally:
        if driver:
            driver.quit()
            print("üö™ ƒê√£ ƒë√≥ng Selenium Driver.")
